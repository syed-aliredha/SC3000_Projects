{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124a869a",
   "metadata": {},
   "source": [
    "### Step 1: Install necesscary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b82f8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "     ---------------------------------------- 0.0/40.1 kB ? eta -:--:--\n",
      "     ---------------------------------------- 40.1/40.1 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.0)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.22.1-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting click>=8.0.1 (from wandb)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wandb) (2.10.5)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.39.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\huang\\appdata\\roaming\\python\\python311\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.11.11)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3->wandb) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.18.3)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\huang\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.6 MB 58.8 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.2/11.6 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.6 MB 23.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.6/11.6 MB 29.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.4/11.6 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.4/11.6 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 40.9 MB/s eta 0:00:00\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "   ---------------------------------------- 0.0/503.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 503.6/503.6 kB 30.8 MB/s eta 0:00:00\n",
      "Downloading wandb-0.22.1-py3-none-win_amd64.whl (18.8 MB)\n",
      "   ---------------------------------------- 0.0/18.8 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.4/18.8 MB 73.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.9/18.8 MB 63.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.2/18.8 MB 65.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 13.0/18.8 MB 65.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.1/18.8 MB 65.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 18.2/18.8 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.8/18.8 MB 65.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.8/18.8 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.3/107.3 kB 6.1 MB/s eta 0:00:00\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "   ---------------------------------------- 0.0/119.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 119.7/119.7 kB 6.8 MB/s eta 0:00:00\n",
      "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "   ---------------------------------------- 0.0/564.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 564.3/564.3 kB 34.6 MB/s eta 0:00:00\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading protobuf-6.32.1-cp310-abi3-win_amd64.whl (435 kB)\n",
      "   ---------------------------------------- 0.0/435.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 435.7/435.7 kB 26.6 MB/s eta 0:00:00\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 3.8/26.2 MB 121.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.8/26.2 MB 82.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.5/26.2 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 15.7/26.2 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.8/26.2 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.3/26.2 MB 72.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.3/26.2 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.8/26.2 MB 50.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.2 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 34.4 MB/s eta 0:00:00\n",
      "Using cached safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading sentry_sdk-2.39.0-py2.py3-none-any.whl (370 kB)\n",
      "   ---------------------------------------- 0.0/370.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 370.9/370.9 kB 22.5 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.7/2.7 MB 85.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 56.7 MB/s eta 0:00:00\n",
      "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: xxhash, smmap, sentry-sdk, safetensors, pyarrow, protobuf, dill, click, multiprocess, huggingface-hub, gitdb, tokenizers, gitpython, wandb, transformers, datasets\n",
      "Successfully installed click-8.3.0 datasets-4.1.1 dill-0.4.0 gitdb-4.0.12 gitpython-3.1.45 huggingface-hub-0.35.3 multiprocess-0.70.16 protobuf-6.32.1 pyarrow-21.0.0 safetensors-0.6.2 sentry-sdk-2.39.0 smmap-5.0.2 tokenizers-0.22.1 transformers-4.56.2 wandb-0.22.1 xxhash-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install torch numpy transformers datasets tiktoken wandb tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9de0",
   "metadata": {},
   "source": [
    "### Step 2: Package imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876dd92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pickle\n",
    "from model import GPT, GPTConfig\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# Configuration\n",
    "beta = 0.5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "base_lr = 1e-4\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "max_length =64\n",
    "num_samples = 1\n",
    "max_new_tokens = 200\n",
    "temperature = 0.8\n",
    "top_k = 200\n",
    "# tokenizer\n",
    "with open(\"../sft/meta.pkl\", \"rb\") as f:\n",
    "    meta = pickle.load(f)\n",
    "stoi, itos = meta[\"stoi\"], meta[\"itos\"]\n",
    "def encode(s): return [stoi[c] for c in s]\n",
    "def decode(l): return ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d35e6",
   "metadata": {},
   "source": [
    "### Step 3: Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03655c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logprob(input_ids):\n",
    "    inputs = input_ids[:, :-1]\n",
    "    targets = input_ids[:, 1:]\n",
    "    logits, _ = gpt(inputs, full_seq=True)\n",
    "    B, T, V = logits.size()\n",
    "    logits_flat = logits.reshape(-1, V)\n",
    "    targets_flat = targets.reshape(-1)\n",
    "    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=0, reduction='none')\n",
    "    loss = loss.reshape(B, T)\n",
    "    attention_mask = (targets != 0).float()\n",
    "    loss = (loss * attention_mask).sum(dim=1) / attention_mask.sum(dim=1)\n",
    "    return -loss \n",
    "\n",
    "def pad_or_truncate(seq, max_length):\n",
    "    return seq[-max_length:] if len(seq) > max_length else seq + [0] * (max_length - len(seq))\n",
    "\n",
    "def get_batches(lines, batch_size):\n",
    "    random.shuffle(lines)\n",
    "    #for l in lines:\n",
    "    #    print(l[1])\n",
    "    for i in range(0, len(lines), batch_size):\n",
    "        batch = lines[i:i+batch_size]\n",
    "        if len(batch) < batch_size:\n",
    "            continue\n",
    "        neg_inputs = [pad_or_truncate(encode(p['negative'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        pos_inputs = [pad_or_truncate(encode(p['positive'] + '\\n\\n\\n\\n'), max_length) for p in batch]\n",
    "        neg_tensor = torch.tensor(neg_inputs, dtype=torch.long, device=device)\n",
    "        pos_tensor = torch.tensor(pos_inputs, dtype=torch.long, device=device)\n",
    "        yield neg_tensor, pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dc9771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100k questions in questions.txt and full Q+A lines in qa.txt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "N = 100_000\n",
    "questions_file = \"questions.txt\"\n",
    "qa_file = \"qa.txt\"\n",
    "\n",
    "def make_direct():\n",
    "    op = random.choice([\"+\", \"-\", \"*\", \"/\"])\n",
    "    a, b = random.randint(1, 100), random.randint(1, 100)\n",
    "        \n",
    "    if op == \"+\":\n",
    "        ans = a + b\n",
    "        explanation = f\"{a}+{b} equals {ans}\"\n",
    "    elif op == \"-\":\n",
    "        ans = a - b\n",
    "        explanation = f\"{a}-{b} equals {ans}\"\n",
    "    elif op == \"*\":\n",
    "        ans = a * b\n",
    "        explanation = f\"{a}*{b} equals {ans}\"\n",
    "    else:\n",
    "        a = a * b\n",
    "        ans = a // b\n",
    "        explanation = f\"{a}/{b} equals {ans}\"\n",
    "\n",
    "    q_str = f\"{a}{op}{b}=?\"\n",
    "    return q_str, f\"{q_str} The answer is {ans} because {explanation}.\"\n",
    "\n",
    "def make_solve_x():\n",
    "    op = random.choice([\"+\", \"-\", \"*\", \"/\"])\n",
    "\n",
    "    ans = random.randint(1, 100)\n",
    "    b = random.randint(1, 100)\n",
    "    \n",
    "    if op == \"+\":\n",
    "        rhs = ans + b\n",
    "        if random.randint(0,1) == 0:\n",
    "            q_str = f\"x+{b}={rhs}, x=?\"\n",
    "        else:\n",
    "            q_str = f\"{b}+x={rhs}, x=?\"\n",
    "        explanation = f\"{rhs}-{b} equals to {ans}\"\n",
    "\n",
    "    elif op == \"-\":\n",
    "        if random.randint(0,1) == 0:\n",
    "            rhs = ans - b\n",
    "            q_str = f\"x-{b}={rhs}, x=?\"\n",
    "            explanation = f\"{rhs}+{b} equals to {ans}\"\n",
    "        else:\n",
    "            rhs = b - ans\n",
    "            q_str = f\"{b}-x={rhs}, x=?\"\n",
    "            if rhs > 0:\n",
    "                explanation = f\"{b}-{rhs} equals to {ans}\"\n",
    "            else:\n",
    "                explanation = f\"{b}+{-rhs} equals to {ans}\"\n",
    "        \n",
    "    elif op == \"*\":\n",
    "        rhs = ans * b\n",
    "        if random.randint(0,1) == 0:\n",
    "            q_str = f\"x*{b}={rhs}, x=?\"\n",
    "        else:\n",
    "            q_str = f\"{b}*x={rhs}, x=?\"\n",
    "        explanation = f\"{rhs}/{b} equals to {ans}\"\n",
    "    else:\n",
    "        rhs = ans \n",
    "        if random.randint(0,1) == 0:\n",
    "            ans = ans * b\n",
    "            rhs = ans // b\n",
    "            q_str = f\"x/{b}={rhs}, x=?\"\n",
    "            explanation = f\"{rhs}*{b} equals to {ans}\"\n",
    "        else:\n",
    "            b = ans * b\n",
    "            rhs = b // ans\n",
    "            q_str = f\"{b}/x={rhs}, x=?\"\n",
    "            explanation = f\"{b}/{rhs} equals to {ans}\"\n",
    "    return q_str, f\"{q_str} The answer is {ans} because {explanation}.\"\n",
    "\n",
    "\n",
    "generators = [make_direct, make_solve_x]\n",
    "\n",
    "with open(questions_file, \"w\") as fq, open(qa_file, \"w\") as fqa:\n",
    "    for _ in range(N):\n",
    "        q, qa = random.choice(generators)()\n",
    "        fq.write(q + \"\\n\")\n",
    "        fqa.write(qa + \"\\n\")\n",
    "\n",
    "print(\"Generated 100k questions in questions.txt and full Q+A lines in qa.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d9eba",
   "metadata": {},
   "source": [
    "### Step 4: Load the pretrained NanoGPT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../sft/gpt.pt\", map_location=device)\n",
    "gptconf = GPTConfig(**ckpt['model_args'])\n",
    "gpt = GPT(gptconf)\n",
    "state_dict = ckpt['model']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k in list(state_dict.keys()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "gpt.to(device).train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feafc5a",
   "metadata": {},
   "source": [
    "### Step 5: Load Data (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7edf3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from ./data/pos_neg_pairs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f81f",
   "metadata": {},
   "source": [
    "### Step 6: Build the optimizer and scheduler (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df0c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommend to use the AdamW optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b66199",
   "metadata": {},
   "source": [
    "### Step 7: Begin training (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ebeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps = len(lines) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    pbar = tqdm(get_batches(lines, batch_size))\n",
    "    for step, (neg_tensor,pos_tensor) in enumerate(pbar):\n",
    "        ###########################################################\n",
    "        # Please complete the training code here!\n",
    "        # Examples: \n",
    "        # ...\n",
    "        # neg_logprob\n",
    "        # pos_logprob \n",
    "        # loss = -F.logsigmoid((pos_logprob - neg_logprob) / beta).mean() - pos_logprob.mean() * 0.1 \n",
    "        # ...\n",
    "        ###########################################################\n",
    "    ckpt_path = f\"./dpo.pt\"\n",
    "    torch.save({\n",
    "        \"model_state_dict\": gpt.state_dict(),\n",
    "        \"model_args\": ckpt['model_args'],\n",
    "    }, ckpt_path)\n",
    "    print(f\"Saved checkpoint to {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7f2ab",
   "metadata": {},
   "source": [
    "### Step 8: Begin testing (**students are required to complete this part!**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09027262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "ckpt_path = \"../dpo/dpo.pt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "gptconf = GPTConfig(**checkpoint['model_args'])\n",
    "gpt = GPT(gptconf).cuda()\n",
    "try:\n",
    "    state_dict = checkpoint['model']\n",
    "except:\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "gpt.load_state_dict(state_dict)\n",
    "# Test\n",
    "gpt.eval()\n",
    "test_set = [\"17+19=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\", \"x*11=44,x=?\", \"3*17=?\", \"72/4=?\", \"72-x=34,x=?\"]\n",
    "with torch.no_grad():\n",
    "    for prompt in test_set: \n",
    "        prompt_ids = encode(prompt)\n",
    "        ###########################################################\n",
    "        # Please complete the test code here!\n",
    "        # ...\n",
    "        # gpt.generate(x, max_new_tokens, temperature=temperature, top_k=top_k)\n",
    "        # ...\n",
    "        ###########################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
